scala_library(
    name = "lib",
    srcs = glob(["src/main/**/*.scala"]),
    format = select({
        "//tools/config:scala_2_13": False,  # Disable for 2.13
        "//conditions:default": True,  # Enable for other versions
    }),
    visibility = ["//visibility:public"],
    deps = _FLINK_DEPS + [
        "//aggregator:lib",
        "//api:lib",
        "//api:thrift_java",
        "//online:lib",
        "//tools/build_rules/spark:spark-exec",
        maven_artifact_with_suffix("org.scala-lang.modules:scala-java8-compat"),
        maven_artifact_with_suffix("org.scala-lang.modules:scala-collection-compat"),
        maven_artifact_with_suffix("org.rogach:scallop"),
        maven_artifact("io.dropwizard.metrics:metrics-core"),
        maven_artifact("org.apache.kafka:kafka-clients"),
        maven_artifact("org.slf4j:slf4j-api"),
        maven_artifact("org.apache.logging.log4j:log4j-api"),
        maven_artifact("org.apache.logging.log4j:log4j-core"),
        maven_artifact("org.apache.logging.log4j:log4j-slf4j-impl"),
        maven_artifact("org.apache.avro:avro"),
        maven_artifact("io.confluent:kafka-schema-registry-client"),
        maven_artifact("io.confluent:kafka-protobuf-provider"),
        maven_artifact("org.apache.hadoop:hadoop-common"),
        maven_artifact("org.apache.hadoop:hadoop-client-api"),
        maven_artifact("org.apache.hadoop:hadoop-yarn-api"),
        maven_artifact("org.apache.commons:commons-lang3"),
    ],
)

test_deps = _FLINK_TEST_DEPS + _SCALA_TEST_DEPS + [
    ":lib",
    "//online:lib",
    "//api:thrift_java",
    "//api:lib",
    "//aggregator:lib",
    "//tools/build_rules/spark:spark-exec",
    maven_artifact_with_suffix("org.scala-lang.modules:scala-java8-compat"),
    maven_artifact_with_suffix("org.scala-lang.modules:scala-collection-compat"),
    maven_artifact("org.slf4j:slf4j-api"),
    maven_artifact("org.apache.logging.log4j:log4j-api"),
    maven_artifact("org.apache.logging.log4j:log4j-core"),
    maven_artifact("org.apache.logging.log4j:log4j-slf4j-impl"),
    maven_artifact("org.apache.avro:avro"),
    maven_artifact("io.confluent:kafka-schema-registry-client"),
    maven_artifact("io.confluent:kafka-protobuf-provider"),
    maven_artifact("org.apache.kafka:kafka-clients"),
    maven_artifact("com.google.protobuf:protobuf-java"),
    maven_artifact("org.apache.hadoop:hadoop-common"),
    maven_artifact("org.apache.hadoop:hadoop-client-api"),
]

scala_library(
    name = "test_lib",
    srcs = glob(["src/test/**/*.scala"]),
    format = select({
        "//tools/config:scala_2_13": False,  # Disable for 2.13
        "//conditions:default": True,  # Enable for other versions
    }),
    visibility = ["//visibility:public"],
    deps = test_deps,
)

scala_test_suite(
    name = "tests",
    srcs = glob(["src/test/**/*.scala"]),
    # defined in prelude_bazel file
    jvm_flags = _JVM_FLAGS_FOR_ACCESSING_BASE_JAVA_CLASSES,
    visibility = ["//visibility:public"],
    deps = test_deps + [":test_lib"],
)

jvm_binary(
    name = "flink_assembly",
    # To exclude runtime dependencies not needed for flink environment in the cluster
    # otherwise we run into version conflict errors
    deploy_env = ["//tools/build_rules/flink:flink"],
    main_class = "ai.chronon.flink.FlinkJob",
    runtime_deps = [":lib"],
)

jvm_binary(
    name = "flink_kafka_assembly",
    # To exclude runtime dependencies not needed for flink environment in the cluster
    # otherwise we run into version conflict errors
    deploy_env = ["//tools/build_rules/flink:flink"],
    main_class = "ai.chronon.flink.FlinkKafkaBeaconEventDriver",
    runtime_deps = [":lib"],
)
